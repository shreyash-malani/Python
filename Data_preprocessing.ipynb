{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "32f9e1b6-33da-475f-a115-6028fd769b79",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original Data : \n",
      "    Country   Age   Salary Purchased\n",
      "0   France  44.0  72000.0        No\n",
      "1    Spain  27.0  48000.0       Yes\n",
      "2  Germany  30.0  54000.0        No\n",
      "3    Spain  38.0  61000.0        No\n",
      "4  Germany  40.0      NaN       Yes\n",
      "5   France  35.0  58000.0       Yes\n",
      "6    Spain   NaN  52000.0        No\n",
      "7   France  48.0  79000.0       Yes\n",
      "8  Germany  50.0  83000.0        No\n",
      "9   France  37.0  67000.0       Yes\n",
      "transform Data : \n",
      " [['France' 44.0 72000.0]\n",
      " ['Spain' 27.0 48000.0]\n",
      " ['Germany' 30.0 54000.0]\n",
      " ['Spain' 38.0 61000.0]\n",
      " ['Germany' 40.0 63777.77777777778]\n",
      " ['France' 35.0 58000.0]\n",
      " ['Spain' 38.77777777777778 52000.0]\n",
      " ['France' 48.0 79000.0]\n",
      " ['Germany' 50.0 83000.0]\n",
      " ['France' 37.0 67000.0]]\n",
      "For Non-Numerical-Country- data For X Part :\n",
      " [[1.0 0.0 0.0 44.0 72000.0]\n",
      " [0.0 0.0 1.0 27.0 48000.0]\n",
      " [0.0 1.0 0.0 30.0 54000.0]\n",
      " [0.0 0.0 1.0 38.0 61000.0]\n",
      " [0.0 1.0 0.0 40.0 63777.77777777778]\n",
      " [1.0 0.0 0.0 35.0 58000.0]\n",
      " [0.0 0.0 1.0 38.77777777777778 52000.0]\n",
      " [1.0 0.0 0.0 48.0 79000.0]\n",
      " [0.0 1.0 0.0 50.0 83000.0]\n",
      " [1.0 0.0 0.0 37.0 67000.0]]\n",
      "For Y Part : \n",
      " [0 1 0 0 1 1 0 1 0 1]\n",
      "X Part of Train : [['Spain' 38.77777777777778 52000.0]\n",
      " ['Germany' 40.0 63777.77777777778]\n",
      " ['France' 44.0 72000.0]\n",
      " ['Spain' 38.0 61000.0]\n",
      " ['Spain' 27.0 48000.0]\n",
      " ['France' 48.0 79000.0]\n",
      " ['Germany' 50.0 83000.0]\n",
      " ['France' 35.0 58000.0]]\n",
      "Y Part of Train : [0 1 0 0 1 1 0 1]\n",
      "Normalised X Part of Train :\n",
      " [[0.5120772946859904 0.11428571428571432]\n",
      " [0.5652173913043479 0.45079365079365075]\n",
      " [0.7391304347826089 0.6857142857142855]\n",
      " [0.4782608695652175 0.37142857142857144]\n",
      " [0.0 0.0]\n",
      " [0.9130434782608696 0.8857142857142857]\n",
      " [1.0 1.0]\n",
      " [0.34782608695652173 0.2857142857142856]]\n",
      "Normalised X Part of TEST :\n",
      " [[0.1304347826086958 0.17142857142857149]\n",
      " [0.43478260869565233 0.5428571428571427]]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "df=pd.read_csv(\"Data.csv\")\n",
    "print('Original Data : \\n',df)\n",
    "\n",
    "x = df.iloc[:,:-1].values\n",
    "y = df.iloc[:,-1].values\n",
    "\n",
    "from sklearn.impute import SimpleImputer\n",
    "imp = SimpleImputer(missing_values = np.nan , strategy = 'mean')\n",
    "imp.fit(x[:,1:3])\n",
    "x[:,1:3]=imp.transform(x[:,1:3])\n",
    "print('transform Data : \\n',x)\n",
    "\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "T = ColumnTransformer(transformers=[('encoder', OneHotEncoder(), [0])], remainder = 'passthrough')\n",
    "P = np.array(T.fit_transform(x))\n",
    "print('For Non-Numerical-Country- data For X Part :\\n',P)\n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "L = LabelEncoder()\n",
    "y = L.fit_transform(y)\n",
    "print('For Y Part : \\n',y)\n",
    "\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size = 0.2, random_state = 1)\n",
    "print(\"X Part of Train :\",x_train)\n",
    "print(\"Y Part of Train :\",y_train)\n",
    "\n",
    "# Normalization Or Min_Max Scale\n",
    "# X_min = (X - X_min) / (X_min - X_max)\n",
    "\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "nm = MinMaxScaler()\n",
    "# x_train[:, 3:] = nm.fit_transform(x_train[:, 3:])\n",
    "# x_test[:, 3:] = nm.transform(x_test[:, 3:])\n",
    "\n",
    "x_train[:, 1:3] = nm.fit_transform(x_train[:, 1:3])  # Adjust based on your actual data columns\n",
    "x_test[:, 1:3] = nm.transform(x_test[:, 1:3])\n",
    "\n",
    "print(\"Normalised X Part of Train :\\n\",x_train[:, 1:3])\n",
    "print(\"Normalised X Part of TEST :\\n\",x_test[:, 1:3])\n",
    "\n",
    "\n",
    "# Splitting the dataset into the Training set and Test set\n",
    "# from sklearn.model_selection import train_test_split\n",
    "# x_train, x_test, y_train, y_test = train_test_split(x, y, test_size = 0.2, random_state = 1)\n",
    "# print(x_train)\n",
    "# print(x_test)\n",
    "# print(y_train)\n",
    "# print(y_test)\n",
    "\n",
    "# # Feature Scaling\n",
    "# from sklearn.preprocessing import StandardScaler\n",
    "# sc = StandardScaler()\n",
    "# x_train[:, 3:] = sc.fit_transform(x_train[:, 3:])\n",
    "# x_test[:, 3:] = sc.transform(x_test[:, 3:])\n",
    "# print(x_train)\n",
    "# print(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8034812-1557-484d-84e7-89585977b8c2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
